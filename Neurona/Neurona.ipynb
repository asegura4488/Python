{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_prep import features,targets,features_test,targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "NHidden = 2   # Unidades en la capa escondida\n",
    "epochs = 1000 # iteraciones sobre conjunto de entrenamiento\n",
    "alpha = 0.05  # Taza de aprendizaje\n",
    "\n",
    "UCost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 6)\n"
     ]
    }
   ],
   "source": [
    "# Numero de ejemplos de entrenamiento \n",
    "# Numero de entradas que tiene cada ejemplo\n",
    "m, k = features.shape\n",
    "print(m,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "# Inicializacion de pesos, peque√±os\n",
    "\n",
    "hidden_input = np.random.normal(scale = 1/k**0.5, size = (k,NHidden))\n",
    "hidden_output = np.random.normal(scale = 1/k**0.5, size = NHidden)\n",
    "\n",
    "print(hidden_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '--- epochs ---', 0.22747155627454319)\n",
      "(10, '--- epochs ---', 0.2271717992060495)\n",
      "(20, '--- epochs ---', 0.22687912541274677)\n",
      "(30, '--- epochs ---', 0.22659332378327968)\n",
      "(40, '--- epochs ---', 0.22631418980332987)\n",
      "(50, '--- epochs ---', 0.22604152536121827)\n",
      "(60, '--- epochs ---', 0.22577513855778888)\n",
      "(70, '--- epochs ---', 0.2255148435206119)\n",
      "(80, '--- epochs ---', 0.22526046022253546)\n",
      "(90, '--- epochs ---', 0.22501181430458642)\n",
      "(100, '--- epochs ---', 0.2247687369032304)\n",
      "(110, '--- epochs ---', 0.224531064481965)\n",
      "(120, '--- epochs ---', 0.22429863866723285)\n",
      "(130, '--- epochs ---', 0.22407130608861883)\n",
      "(140, '--- epochs ---', 0.22384891822329306)\n",
      "(150, '--- epochs ---', 0.22363133124465184)\n",
      "(160, '--- epochs ---', 0.2234184058751056)\n",
      "(170, '--- epochs ---', 0.22321000724295628)\n",
      "(180, '--- epochs ---', 0.2230060047433)\n",
      "(190, '--- epochs ---', 0.22280627190288935)\n",
      "(200, '--- epochs ---', 0.22261068624888788)\n",
      "(210, '--- epochs ---', 0.22241912918144036)\n",
      "(220, '--- epochs ---', 0.22223148584998603)\n",
      "(230, '--- epochs ---', 0.22204764503323784)\n",
      "(240, '--- epochs ---', 0.22186749902274944)\n",
      "(250, '--- epochs ---', 0.22169094350998791)\n",
      "(260, '--- epochs ---', 0.22151787747683696)\n",
      "(270, '--- epochs ---', 0.22134820308944236)\n",
      "(280, '--- epochs ---', 0.22118182559532812)\n",
      "(290, '--- epochs ---', 0.22101865322369033)\n",
      "(300, '--- epochs ---', 0.2208585970887995)\n",
      "(310, '--- epochs ---', 0.2207015710964221)\n",
      "(320, '--- epochs ---', 0.22054749185318698)\n",
      "(330, '--- epochs ---', 0.22039627857881372)\n",
      "(340, '--- epochs ---', 0.22024785302112607)\n",
      "(350, '--- epochs ---', 0.2201021393737744)\n",
      "(360, '--- epochs ---', 0.21995906419658856)\n",
      "(370, '--- epochs ---', 0.2198185563384869)\n",
      "(380, '--- epochs ---', 0.21968054686286959)\n",
      "(390, '--- epochs ---', 0.21954496897541867)\n",
      "(400, '--- epochs ---', 0.2194117579542409)\n",
      "(410, '--- epochs ---', 0.2192808510822779)\n",
      "(420, '--- epochs ---', 0.2191521875819168)\n",
      "(430, '--- epochs ---', 0.2190257085517369)\n",
      "(440, '--- epochs ---', 0.2189013569053233)\n",
      "(450, '--- epochs ---', 0.21877907731208848)\n",
      "(460, '--- epochs ---', 0.21865881614003466)\n",
      "(470, '--- epochs ---', 0.21854052140039976)\n",
      "(480, '--- epochs ---', 0.2184241426941279)\n",
      "(490, '--- epochs ---', 0.21830963116010252)\n",
      "(500, '--- epochs ---', 0.2181969394250941)\n",
      "(510, '--- epochs ---', 0.21808602155535833)\n",
      "(520, '--- epochs ---', 0.21797683300984008)\n",
      "(530, '--- epochs ---', 0.21786933059492578)\n",
      "(540, '--- epochs ---', 0.2177634724206982)\n",
      "(550, '--- epochs ---', 0.21765921785864242)\n",
      "(560, '--- epochs ---', 0.217556527500754)\n",
      "(570, '--- epochs ---', 0.2174553631200114)\n",
      "(580, '--- epochs ---', 0.21735568763215685)\n",
      "(590, '--- epochs ---', 0.2172574650587515)\n",
      "(600, '--- epochs ---', 0.2171606604914597)\n",
      "(610, '--- epochs ---', 0.21706524005752065)\n",
      "(620, '--- epochs ---', 0.21697117088636908)\n",
      "(630, '--- epochs ---', 0.21687842107736913)\n",
      "(640, '--- epochs ---', 0.21678695966861983)\n",
      "(650, '--- epochs ---', 0.2166967566068015)\n",
      "(660, '--- epochs ---', 0.21660778271802333)\n",
      "(670, '--- epochs ---', 0.216520009679643)\n",
      "(680, '--- epochs ---', 0.21643340999302316)\n",
      "(690, '--- epochs ---', 0.21634795695719528)\n",
      "(700, '--- epochs ---', 0.21626362464339882)\n",
      "(710, '--- epochs ---', 0.21618038787046515)\n",
      "(720, '--- epochs ---', 0.21609822218102315)\n",
      "(730, '--- epochs ---', 0.2160171038184939)\n",
      "(740, '--- epochs ---', 0.21593700970484578)\n",
      "(750, '--- epochs ---', 0.21585791741909463)\n",
      "(760, '--- epochs ---', 0.21577980517650996)\n",
      "(770, '--- epochs ---', 0.21570265180851703)\n",
      "(780, '--- epochs ---', 0.21562643674325926)\n",
      "(790, '--- epochs ---', 0.2155511399868076)\n",
      "(800, '--- epochs ---', 0.21547674210499088)\n",
      "(810, '--- epochs ---', 0.21540322420582633)\n",
      "(820, '--- epochs ---', 0.21533056792252994)\n",
      "(830, '--- epochs ---', 0.21525875539709097)\n",
      "(840, '--- epochs ---', 0.2151877692643834)\n",
      "(850, '--- epochs ---', 0.2151175926368049)\n",
      "(860, '--- epochs ---', 0.2150482090894202)\n",
      "(870, '--- epochs ---', 0.21497960264559218)\n",
      "(880, '--- epochs ---', 0.21491175776308766)\n",
      "(890, '--- epochs ---', 0.21484465932063815)\n",
      "(900, '--- epochs ---', 0.2147782926049394)\n",
      "(910, '--- epochs ---', 0.21471264329808126)\n",
      "(920, '--- epochs ---', 0.21464769746538576)\n",
      "(930, '--- epochs ---', 0.2145834415436442)\n",
      "(940, '--- epochs ---', 0.21451986232973852)\n",
      "(950, '--- epochs ---', 0.21445694696963308)\n",
      "(960, '--- epochs ---', 0.21439468294772698)\n",
      "(970, '--- epochs ---', 0.21433305807655115)\n",
      "(980, '--- epochs ---', 0.21427206048680184)\n",
      "(990, '--- epochs ---', 0.21421167861769763)\n"
     ]
    }
   ],
   "source": [
    "# Tranning\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Gradient\n",
    "    \n",
    "    Grad_hidden_input  = np.zeros(hidden_input.shape)\n",
    "    Grad_hidden_output = np.zeros(hidden_output.shape)\n",
    "    \n",
    "    # Itera sobre el conjunto de entrenamiento\n",
    "    \n",
    "    for x,y in zip(features.values, targets):\n",
    "        \n",
    "        # forward pass\n",
    "        \n",
    "        z = sigmoide(np.matmul(x,hidden_input))\n",
    "        # Prediction\n",
    "        y_ = sigmoide(np.matmul(hidden_output,z))\n",
    "        \n",
    "        # backward_pass\n",
    "        Error = (y - y_) * y_ *(1- y_)\n",
    "        #print(Error)\n",
    "        \n",
    "        hidden_error = np.dot(Error, hidden_output) * z * (1 - z)\n",
    "    \n",
    "        # Update the gradients\n",
    "        Grad_hidden_input += hidden_error * x[:,None]\n",
    "        Grad_hidden_output += Error * z\n",
    "    \n",
    "    \n",
    "    # Update the weights\n",
    "    hidden_input += alpha * Grad_hidden_input / m\n",
    "    hidden_output += alpha * Grad_hidden_output / m\n",
    "        \n",
    "    #print(Grad_hidden_input)\n",
    "    if e % (epochs / 100) == 0:\n",
    "        \n",
    "        \n",
    "        z = sigmoide(np.dot(features.values,hidden_input))\n",
    "        y_ = sigmoide( np.dot(z, hidden_output) )\n",
    "        \n",
    "        # Cost function\n",
    "        Cost = np.mean((y_ - targets)**2)\n",
    "        \n",
    "        if UCost and UCost < Cost:\n",
    "            print(e, 'Cost is going up', Cost)\n",
    "        else:\n",
    "            print(e, '--- epochs ---' , Cost)\n",
    "            \n",
    "        UCost = Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.650\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "\n",
    "z = sigmoide(np.dot(features_test,hidden_input))\n",
    "y_= sigmoide( np.dot(z, hidden_output) )\n",
    "       \n",
    "predicciones = y_ > 0.5\n",
    "\n",
    "precision = np.mean(predicciones == targets_test)\n",
    "print(\"Precision: {:.3f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
